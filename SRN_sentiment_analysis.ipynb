{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data sourced from https://www.kaggle.com/datasets/utkarshxy/stock-markettweets-lexicon-data  \n",
    "Some data processing abridged from https://www.kaggle.com/code/juniorbueno/stock-market-sentimen-bert-tokenizer  \n",
    "Various code snippets from COMP9444 assignment 'paraphrased'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to install (via pip3): torch, matplotlib, numpy, nltk.  \n",
    "You will also need to run (with python3 in terminal)  \n",
    "`>>>import nltk`  \n",
    "`>>>nltk.download('stopwords')`  \n",
    "`>>>nltk.download('wordnet')`  \n",
    "`>>>nltk.download('omw-1.4')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1    3685\n",
      "-1    2106\n",
      "Name: Sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from random import shuffle\n",
    "\n",
    "with open('stock_data.csv', encoding='utf8') as csvfile:\n",
    "    df = pd.read_csv(csvfile, delimiter=',')\n",
    "\n",
    "df.dropna(axis=0, how='any', inplace=True)                         # Excludes null-containing rows\n",
    "print(df['Sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "word_frequency_requirement = 4 # the number of times a word has to appear to be given\n",
    "# it's own encoding. All words under this limit are encoded as the same 'unknown' word.\n",
    "train_proportion = 0.8\n",
    "hidden_layer_size = 10\n",
    "learning_rate = 0.005\n",
    "batch_size = 32\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regex removal of various undesirable parts of a tweet\n",
    "def clean_tweet(tweet):\n",
    "  tweet = re.sub(r\"@[A-Za-z0-9]+\", ' ', tweet) # Twitter handle removal\n",
    "  tweet = re.sub(r\"https?://[A-Za-z0-9./]+\", ' ', tweet) # URL removal\n",
    "  tweet = re.sub(r\"[']\", \"\", tweet) # Apostrophe removal\n",
    "  tweet = re.sub(r\"[^a-zA-Z.!?]\", ' ', tweet) # Remove symbols that are not alphabetic or sentence endings\n",
    "  tweet = re.sub(r\"([^a-zA-Z])\", r\" \\1 \", tweet) # Places spaces around sentence endings,\n",
    "  # so they are encoded as their own words, rather than being lumped in with other words.\n",
    "  tweet = re.sub(r\" +\", ' ', tweet) # Excess whitespace removal\n",
    "  tweet = tweet.lower() # Send tweet to lowercase\n",
    "  return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare word lemmatizer and stopwords list for sanitisation\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stops = set(stopwords.words('english'))\n",
    "\n",
    "def tokenize(tweet):\n",
    "    tweet = clean_tweet(tweet)\n",
    "    tweet = filter(lambda w: w not in stops, tweet.strip().split()) # Remove stopwords\n",
    "    return list(map(lemmatizer.lemmatize, tweet)) # Lemmatize words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kicker', 'watchlist', 'xide', 'tit', 'soq', 'pnk', 'cpw', 'bpz', 'aj', 'trade', 'method', 'method', 'see', 'prev', 'post']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[kicker, watchlist, xide, tit, soq, pnk, cpw, ...</td>\n",
       "      <td>[tensor(1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[user, aap, movie, ., return, fea, geed, indic...</td>\n",
       "      <td>[tensor(1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[user, id, afraid, short, amzn, looking, like,...</td>\n",
       "      <td>[tensor(1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[aap, user, current, downtrend, break, ., othe...</td>\n",
       "      <td>[tensor(0)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[monday, relative, weakness, ., nyx, win, tie,...</td>\n",
       "      <td>[tensor(0)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4747</th>\n",
       "      <td>[industry, body, cii, said, discoms, likely, s...</td>\n",
       "      <td>[tensor(0)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4748</th>\n",
       "      <td>[gold, price, slip, r, investor, book, profit,...</td>\n",
       "      <td>[tensor(0)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4749</th>\n",
       "      <td>[worker, bajaj, auto, agreed, wage, cut, perio...</td>\n",
       "      <td>[tensor(1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4750</th>\n",
       "      <td>[sharemarket, live, sensex, day, high, point, ...</td>\n",
       "      <td>[tensor(1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4751</th>\n",
       "      <td>[sensex, nifty, climb, day, high, still, key, ...</td>\n",
       "      <td>[tensor(1)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4752 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text    Sentiment\n",
       "0     [kicker, watchlist, xide, tit, soq, pnk, cpw, ...  [tensor(1)]\n",
       "1     [user, aap, movie, ., return, fea, geed, indic...  [tensor(1)]\n",
       "2     [user, id, afraid, short, amzn, looking, like,...  [tensor(1)]\n",
       "3     [aap, user, current, downtrend, break, ., othe...  [tensor(0)]\n",
       "4     [monday, relative, weakness, ., nyx, win, tie,...  [tensor(0)]\n",
       "...                                                 ...          ...\n",
       "4747  [industry, body, cii, said, discoms, likely, s...  [tensor(0)]\n",
       "4748  [gold, price, slip, r, investor, book, profit,...  [tensor(0)]\n",
       "4749  [worker, bajaj, auto, agreed, wage, cut, perio...  [tensor(1)]\n",
       "4750  [sharemarket, live, sensex, day, high, point, ...  [tensor(1)]\n",
       "4751  [sensex, nifty, climb, day, high, still, key, ...  [tensor(1)]\n",
       "\n",
       "[4752 rows x 2 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "san_df = pd.DataFrame([\n",
    "    df['Text'].map(tokenize),\n",
    "    #df['Sentiment'].map(lambda x: torch.tensor([1,0]) if (x==1) else torch.tensor([0,1]))\n",
    "    df['Sentiment'].map(lambda x: torch.tensor([1]) if (x==1) else torch.tensor([0]))\n",
    "    ]).T\n",
    "    \n",
    "indexes = [i for i, x in enumerate(san_df['Text']) if len(x) <= 5]\n",
    "san_df.drop(indexes, inplace=True)\n",
    "san_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(san_df.Text[0])\n",
    "san_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'kicker': 2,\n",
       "         'watchlist': 27,\n",
       "         'xide': 2,\n",
       "         'tit': 2,\n",
       "         'soq': 1,\n",
       "         'pnk': 1,\n",
       "         'cpw': 2,\n",
       "         'bpz': 1,\n",
       "         'aj': 4,\n",
       "         'trade': 155,\n",
       "         'method': 3,\n",
       "         'see': 163,\n",
       "         'prev': 4,\n",
       "         'post': 49,\n",
       "         'user': 611,\n",
       "         'aap': 781,\n",
       "         'movie': 6,\n",
       "         '.': 6656,\n",
       "         'return': 22,\n",
       "         'fea': 1,\n",
       "         'geed': 1,\n",
       "         'indicator': 17,\n",
       "         'year': 126,\n",
       "         'awesome': 8,\n",
       "         'id': 11,\n",
       "         'afraid': 3,\n",
       "         'short': 415,\n",
       "         'amzn': 90,\n",
       "         'looking': 107,\n",
       "         'like': 256,\n",
       "         'near': 45,\n",
       "         'monopoly': 2,\n",
       "         'ebooks': 1,\n",
       "         'infrastructure': 2,\n",
       "         'service': 13,\n",
       "         'current': 15,\n",
       "         'downtrend': 13,\n",
       "         'break': 148,\n",
       "         'otherwise': 3,\n",
       "         'term': 85,\n",
       "         'correction': 12,\n",
       "         'med': 3,\n",
       "         'monday': 28,\n",
       "         'relative': 7,\n",
       "         'weakness': 19,\n",
       "         'nyx': 2,\n",
       "         'win': 20,\n",
       "         'tie': 3,\n",
       "         'tap': 6,\n",
       "         'ice': 7,\n",
       "         'int': 5,\n",
       "         'bmc': 1,\n",
       "         'aon': 5,\n",
       "         'c': 95,\n",
       "         'chk': 21,\n",
       "         'biib': 3,\n",
       "         'goog': 186,\n",
       "         'ower': 4,\n",
       "         'trend': 83,\n",
       "         'line': 99,\n",
       "         'channel': 35,\n",
       "         'test': 43,\n",
       "         'volume': 292,\n",
       "         'support': 118,\n",
       "         'watch': 185,\n",
       "         'tomorrow': 71,\n",
       "         'ong': 138,\n",
       "         'entry': 58,\n",
       "         'im': 75,\n",
       "         'assuming': 4,\n",
       "         'fcx': 23,\n",
       "         'open': 100,\n",
       "         'trigger': 16,\n",
       "         'buy': 203,\n",
       "         'still': 190,\n",
       "         'much': 61,\n",
       "         'setup': 49,\n",
       "         'really': 52,\n",
       "         'worry': 4,\n",
       "         'everyone': 21,\n",
       "         'expects': 8,\n",
       "         'market': 283,\n",
       "         'rally': 27,\n",
       "         'usually': 8,\n",
       "         'exact': 5,\n",
       "         'opposite': 1,\n",
       "         'happens': 13,\n",
       "         'every': 22,\n",
       "         'time': 184,\n",
       "         'shall': 1,\n",
       "         'soon': 58,\n",
       "         'bac': 176,\n",
       "         'spx': 48,\n",
       "         'jpm': 38,\n",
       "         'gamcos': 1,\n",
       "         'arry': 4,\n",
       "         'haverty': 1,\n",
       "         'apple': 60,\n",
       "         'extremely': 7,\n",
       "         'cheap': 23,\n",
       "         'great': 77,\n",
       "         'video': 38,\n",
       "         '!': 687,\n",
       "         'maykiljil': 1,\n",
       "         'posted': 19,\n",
       "         'agree': 10,\n",
       "         'msft': 31,\n",
       "         'going': 108,\n",
       "         'higher': 155,\n",
       "         'possibly': 7,\n",
       "         'north': 4,\n",
       "         'momentum': 20,\n",
       "         'coming': 62,\n",
       "         'back': 180,\n",
       "         'etfc': 3,\n",
       "         'broke': 39,\n",
       "         'resistance': 83,\n",
       "         'solid': 26,\n",
       "         'friday': 47,\n",
       "         'set': 39,\n",
       "         'ha': 13,\n",
       "         'hitting': 7,\n",
       "         'mean': 23,\n",
       "         'resume': 14,\n",
       "         'targeting': 1,\n",
       "         'level': 76,\n",
       "         'gameplan': 1,\n",
       "         'shot': 31,\n",
       "         'today': 323,\n",
       "         'liked': 4,\n",
       "         'may': 93,\n",
       "         'h': 41,\n",
       "         'oc': 17,\n",
       "         'weekly': 130,\n",
       "         'july': 7,\n",
       "         'gapping': 1,\n",
       "         'well': 92,\n",
       "         'ideal': 4,\n",
       "         'pull': 23,\n",
       "         'least': 14,\n",
       "         'list': 75,\n",
       "         'particularly': 1,\n",
       "         'fisv': 1,\n",
       "         'syk': 2,\n",
       "         'hold': 66,\n",
       "         'type': 5,\n",
       "         'check': 29,\n",
       "         'free': 17,\n",
       "         'ng': 40,\n",
       "         'nice': 169,\n",
       "         'pnf': 1,\n",
       "         'breakout': 118,\n",
       "         'need': 89,\n",
       "         'follow': 31,\n",
       "         'thru': 26,\n",
       "         'wont': 19,\n",
       "         'believe': 12,\n",
       "         'uptrend': 23,\n",
       "         'cross': 26,\n",
       "         'biof': 4,\n",
       "         'want': 64,\n",
       "         'comin': 2,\n",
       "         'v': 99,\n",
       "         'inverted': 3,\n",
       "         'head': 23,\n",
       "         'shoulder': 18,\n",
       "         'play': 52,\n",
       "         'wasnt': 4,\n",
       "         'able': 5,\n",
       "         'catch': 13,\n",
       "         'eye': 23,\n",
       "         'ei': 1,\n",
       "         'close': 150,\n",
       "         'breaking': 58,\n",
       "         'quick': 21,\n",
       "         'late': 20,\n",
       "         'investing': 5,\n",
       "         'good': 211,\n",
       "         'point': 150,\n",
       "         'imho': 32,\n",
       "         'chdn': 1,\n",
       "         'trailing': 30,\n",
       "         'stop': 214,\n",
       "         'prior': 26,\n",
       "         'vome': 11,\n",
       "         'impressive': 3,\n",
       "         'rate': 24,\n",
       "         'probably': 22,\n",
       "         'get': 124,\n",
       "         'share': 125,\n",
       "         'traded': 14,\n",
       "         'adding': 20,\n",
       "         'vxy': 22,\n",
       "         'long': 223,\n",
       "         'bottom': 55,\n",
       "         'also': 51,\n",
       "         'got': 42,\n",
       "         'wpi': 5,\n",
       "         'low': 125,\n",
       "         'repeat': 6,\n",
       "         'global': 61,\n",
       "         'economy': 31,\n",
       "         'better': 43,\n",
       "         'go': 151,\n",
       "         'instead': 8,\n",
       "         'nkd': 46,\n",
       "         'failed': 12,\n",
       "         'price': 161,\n",
       "         'g': 88,\n",
       "         'action': 47,\n",
       "         'far': 34,\n",
       "         'holding': 85,\n",
       "         'deciding': 2,\n",
       "         'whether': 4,\n",
       "         'call': 125,\n",
       "         'stock': 363,\n",
       "         'new': 193,\n",
       "         'target': 112,\n",
       "         'notice': 5,\n",
       "         'shakeout': 5,\n",
       "         'reading': 3,\n",
       "         'dot': 9,\n",
       "         'early': 34,\n",
       "         'move': 170,\n",
       "         'day': 375,\n",
       "         'settle': 10,\n",
       "         'patience': 16,\n",
       "         'coh': 11,\n",
       "         'bwd': 4,\n",
       "         'dt': 13,\n",
       "         'pay': 50,\n",
       "         'obbers': 1,\n",
       "         'hit': 77,\n",
       "         'store': 15,\n",
       "         'paris': 1,\n",
       "         'prefer': 8,\n",
       "         'take': 88,\n",
       "         'merchendise': 1,\n",
       "         'cash': 86,\n",
       "         'bullish': 112,\n",
       "         'axa': 2,\n",
       "         'tip': 6,\n",
       "         'even': 45,\n",
       "         'sign': 18,\n",
       "         'newsletter': 1,\n",
       "         'anything': 9,\n",
       "         'wrong': 14,\n",
       "         'eat': 3,\n",
       "         'crow': 3,\n",
       "         'x': 47,\n",
       "         'due': 22,\n",
       "         'kirby': 2,\n",
       "         'daily': 72,\n",
       "         'around': 53,\n",
       "         'swinging': 1,\n",
       "         'min': 41,\n",
       "         'longs': 14,\n",
       "         'fully': 5,\n",
       "         'added': 32,\n",
       "         'look': 178,\n",
       "         'pop': 39,\n",
       "         'reset': 2,\n",
       "         'stellar': 2,\n",
       "         'swing': 41,\n",
       "         'full': 64,\n",
       "         'position': 102,\n",
       "         'idcc': 7,\n",
       "         'sma': 50,\n",
       "         'acting': 10,\n",
       "         'switched': 2,\n",
       "         'upside': 45,\n",
       "         'month': 71,\n",
       "         'high': 206,\n",
       "         'showing': 18,\n",
       "         'stress': 3,\n",
       "         'two': 40,\n",
       "         'bull': 54,\n",
       "         'flag': 63,\n",
       "         'top': 61,\n",
       "         'traditional': 1,\n",
       "         'figure': 9,\n",
       "         'signal': 35,\n",
       "         'multiyear': 1,\n",
       "         'closed': 26,\n",
       "         'u': 111,\n",
       "         'know': 50,\n",
       "         'rule': 9,\n",
       "         'large': 20,\n",
       "         'cup': 27,\n",
       "         'n': 24,\n",
       "         'handle': 27,\n",
       "         'eog': 3,\n",
       "         'ascending': 9,\n",
       "         'triangle': 144,\n",
       "         'original': 2,\n",
       "         'extension': 3,\n",
       "         'eps': 30,\n",
       "         'feb': 47,\n",
       "         'th': 38,\n",
       "         '?': 430,\n",
       "         'aapl': 42,\n",
       "         'closing': 16,\n",
       "         'w': 65,\n",
       "         'pattern': 55,\n",
       "         'phm': 7,\n",
       "         'pultegroup': 1,\n",
       "         'option': 71,\n",
       "         'bear': 45,\n",
       "         'bet': 29,\n",
       "         'million': 72,\n",
       "         'april': 23,\n",
       "         'displaying': 3,\n",
       "         'ao': 5,\n",
       "         'shd': 17,\n",
       "         'wtw': 4,\n",
       "         'p': 112,\n",
       "         'prepare': 4,\n",
       "         'stall': 2,\n",
       "         'e': 86,\n",
       "         'f': 124,\n",
       "         'monetize': 1,\n",
       "         'electronics': 2,\n",
       "         'make': 70,\n",
       "         'traffic': 4,\n",
       "         'marketplace': 1,\n",
       "         'wake': 6,\n",
       "         'say': 82,\n",
       "         'didnt': 19,\n",
       "         'ebay': 24,\n",
       "         'cvi': 1,\n",
       "         'starting': 18,\n",
       "         'clean': 4,\n",
       "         'book': 13,\n",
       "         'making': 38,\n",
       "         'first': 74,\n",
       "         'yr': 27,\n",
       "         'sam': 2,\n",
       "         'cheer': 1,\n",
       "         'temporary': 3,\n",
       "         'solution': 1,\n",
       "         'economic': 24,\n",
       "         'woe': 1,\n",
       "         'ovti': 7,\n",
       "         'ttm': 7,\n",
       "         'ending': 5,\n",
       "         'oct': 5,\n",
       "         'negative': 26,\n",
       "         'operational': 27,\n",
       "         'flow': 32,\n",
       "         'decline': 27,\n",
       "         'yoy': 4,\n",
       "         'respond': 1,\n",
       "         'positively': 2,\n",
       "         'jobless': 7,\n",
       "         'claim': 10,\n",
       "         'number': 20,\n",
       "         'analyst': 15,\n",
       "         'earnings': 107,\n",
       "         'exacty': 1,\n",
       "         'reporting': 3,\n",
       "         'color': 1,\n",
       "         'intc': 15,\n",
       "         'aa': 13,\n",
       "         'es': 3,\n",
       "         'week': 185,\n",
       "         'away': 26,\n",
       "         'tho': 8,\n",
       "         'season': 2,\n",
       "         'doesnt': 20,\n",
       "         'eay': 2,\n",
       "         'begin': 8,\n",
       "         'cranking': 1,\n",
       "         'til': 5,\n",
       "         'et': 7,\n",
       "         'al': 5,\n",
       "         'idea': 25,\n",
       "         'wo': 2,\n",
       "         'cut': 44,\n",
       "         'dc': 4,\n",
       "         'ath': 5,\n",
       "         'unknown': 1,\n",
       "         'one': 157,\n",
       "         'verse': 1,\n",
       "         'fnf': 1,\n",
       "         'fod': 5,\n",
       "         'tom': 6,\n",
       "         'system': 13,\n",
       "         'predict': 3,\n",
       "         'green': 110,\n",
       "         'candle': 30,\n",
       "         'fitness': 1,\n",
       "         'health': 12,\n",
       "         'apps': 3,\n",
       "         'winner': 16,\n",
       "         'gynormous': 1,\n",
       "         'speculation': 3,\n",
       "         'run': 63,\n",
       "         'nke': 13,\n",
       "         'dime': 3,\n",
       "         'ongs': 4,\n",
       "         'dollar': 34,\n",
       "         'qqq': 23,\n",
       "         'nbelieveable': 1,\n",
       "         'payment': 12,\n",
       "         'vcs': 1,\n",
       "         'chasing': 3,\n",
       "         'easily': 5,\n",
       "         'played': 4,\n",
       "         'public': 10,\n",
       "         'mastercard': 1,\n",
       "         'triggered': 15,\n",
       "         'oex': 2,\n",
       "         'agnx': 1,\n",
       "         'tv': 12,\n",
       "         'vbd': 3,\n",
       "         'ppc': 2,\n",
       "         'exp': 7,\n",
       "         'onty': 4,\n",
       "         'bmn': 2,\n",
       "         'wk': 18,\n",
       "         'chmt': 1,\n",
       "         'fbc': 1,\n",
       "         'isi': 11,\n",
       "         'aig': 12,\n",
       "         'technology': 9,\n",
       "         'software': 9,\n",
       "         'alert': 15,\n",
       "         'went': 20,\n",
       "         'bonkers': 1,\n",
       "         'many': 47,\n",
       "         'pfe': 7,\n",
       "         'host': 1,\n",
       "         'congrats': 5,\n",
       "         'cloud': 13,\n",
       "         'ax': 14,\n",
       "         'wow': 23,\n",
       "         'steel': 3,\n",
       "         'mt': 5,\n",
       "         'dndn': 18,\n",
       "         'broken': 14,\n",
       "         'clear': 24,\n",
       "         'resistanc': 1,\n",
       "         'heavy': 19,\n",
       "         'could': 132,\n",
       "         'headed': 13,\n",
       "         'morning': 38,\n",
       "         'jan': 38,\n",
       "         'expiration': 13,\n",
       "         'path': 3,\n",
       "         'unthreatened': 1,\n",
       "         'unless': 9,\n",
       "         'fails': 3,\n",
       "         'monitor': 5,\n",
       "         'dynamic': 1,\n",
       "         'dec': 15,\n",
       "         'mho': 3,\n",
       "         'tsm': 1,\n",
       "         'ipgp': 1,\n",
       "         'eqix': 7,\n",
       "         'bc': 3,\n",
       "         'bdc': 1,\n",
       "         'ash': 1,\n",
       "         'hoped': 2,\n",
       "         'pick': 30,\n",
       "         'ost': 4,\n",
       "         'gps': 4,\n",
       "         'wa': 1,\n",
       "         'fast': 24,\n",
       "         'fade': 8,\n",
       "         'behaves': 2,\n",
       "         'hn': 4,\n",
       "         'rd': 9,\n",
       "         'pullback': 52,\n",
       "         'enter': 10,\n",
       "         'ascend': 1,\n",
       "         'exten': 1,\n",
       "         'fib': 25,\n",
       "         'subjective': 1,\n",
       "         'kcg': 6,\n",
       "         'thing': 32,\n",
       "         'hmmmm': 2,\n",
       "         'vng': 23,\n",
       "         'huge': 38,\n",
       "         'news': 47,\n",
       "         'patent': 5,\n",
       "         'attorney': 1,\n",
       "         'dan': 1,\n",
       "         'avicher': 2,\n",
       "         'nhod': 2,\n",
       "         'previous': 11,\n",
       "         'american': 16,\n",
       "         'international': 4,\n",
       "         'group': 16,\n",
       "         'trader': 40,\n",
       "         'next': 171,\n",
       "         'sell': 91,\n",
       "         'since': 95,\n",
       "         'consolidation': 35,\n",
       "         'stable': 4,\n",
       "         'pm': 18,\n",
       "         'sony': 1,\n",
       "         'pre': 20,\n",
       "         'owned': 4,\n",
       "         'block': 11,\n",
       "         'tech': 11,\n",
       "         'unearthed': 1,\n",
       "         'sne': 1,\n",
       "         'gme': 6,\n",
       "         'profit': 92,\n",
       "         'last': 116,\n",
       "         'turn': 23,\n",
       "         'light': 10,\n",
       "         'love': 31,\n",
       "         'wynn': 10,\n",
       "         'yesterday': 70,\n",
       "         'wave': 11,\n",
       "         'iv': 3,\n",
       "         'would': 87,\n",
       "         'lower': 107,\n",
       "         'key': 34,\n",
       "         'hod': 17,\n",
       "         'neckline': 5,\n",
       "         'bearish': 45,\n",
       "         'ddd': 80,\n",
       "         'consolidating': 10,\n",
       "         'strong': 83,\n",
       "         'mil': 11,\n",
       "         'plus': 6,\n",
       "         'buying': 72,\n",
       "         'massive': 9,\n",
       "         'squeeze': 23,\n",
       "         'thought': 16,\n",
       "         'story': 16,\n",
       "         'dead': 15,\n",
       "         'kill': 2,\n",
       "         'thesis': 5,\n",
       "         'bk': 11,\n",
       "         'sale': 46,\n",
       "         'nook': 1,\n",
       "         'holiday': 6,\n",
       "         'ac': 1,\n",
       "         'average': 43,\n",
       "         'bounce': 50,\n",
       "         'wightwatchers': 1,\n",
       "         'ad': 10,\n",
       "         'fun': 7,\n",
       "         'regular': 2,\n",
       "         'people': 31,\n",
       "         'interesting': 31,\n",
       "         'dont': 68,\n",
       "         'trust': 5,\n",
       "         'upper': 11,\n",
       "         'exactly': 8,\n",
       "         'spy': 85,\n",
       "         'qe': 4,\n",
       "         'bring': 8,\n",
       "         'geithner': 1,\n",
       "         'extended': 9,\n",
       "         'unexpected': 1,\n",
       "         'fed': 36,\n",
       "         'minute': 32,\n",
       "         'esd': 3,\n",
       "         'panicky': 1,\n",
       "         'nq': 6,\n",
       "         'ncle': 1,\n",
       "         'ben': 2,\n",
       "         'needed': 8,\n",
       "         'spice': 1,\n",
       "         'little': 48,\n",
       "         'bored': 1,\n",
       "         'might': 41,\n",
       "         'control': 5,\n",
       "         'descending': 11,\n",
       "         'trendline': 17,\n",
       "         'fan': 6,\n",
       "         'seeking': 5,\n",
       "         'synthetic': 1,\n",
       "         'add': 27,\n",
       "         'cwst': 2,\n",
       "         'watchn': 1,\n",
       "         'b': 85,\n",
       "         'minimal': 1,\n",
       "         'risk': 33,\n",
       "         'vmw': 12,\n",
       "         'cm': 17,\n",
       "         'keep': 54,\n",
       "         'overniight': 1,\n",
       "         'mmy': 1,\n",
       "         'po': 25,\n",
       "         'bin': 2,\n",
       "         'premarket': 10,\n",
       "         'tmorrow': 2,\n",
       "         'polk': 3,\n",
       "         'vehicle': 5,\n",
       "         'egistrations': 1,\n",
       "         'gm': 9,\n",
       "         'think': 93,\n",
       "         'talked': 3,\n",
       "         'scty': 6,\n",
       "         'angi': 3,\n",
       "         'fio': 20,\n",
       "         'panw': 3,\n",
       "         'jcp': 34,\n",
       "         'yep': 12,\n",
       "         'mnst': 4,\n",
       "         'gpn': 24,\n",
       "         'show': 30,\n",
       "         'someone': 15,\n",
       "         'bought': 59,\n",
       "         'k': 71,\n",
       "         'man': 9,\n",
       "         'skippy': 1,\n",
       "         'made': 39,\n",
       "         'thrown': 1,\n",
       "         'jar': 1,\n",
       "         'hormel': 1,\n",
       "         'big': 123,\n",
       "         'bond': 25,\n",
       "         'zn': 2,\n",
       "         'truly': 2,\n",
       "         'ugly': 9,\n",
       "         'nfp': 1,\n",
       "         'tt': 4,\n",
       "         'wrap': 15,\n",
       "         'addition': 16,\n",
       "         'ist': 23,\n",
       "         'including': 23,\n",
       "         'bcei': 3,\n",
       "         'bji': 3,\n",
       "         'cee': 15,\n",
       "         'son': 2,\n",
       "         'sqnm': 6,\n",
       "         'nx': 8,\n",
       "         'maybe': 31,\n",
       "         'vrng': 1,\n",
       "         'asked': 5,\n",
       "         'judge': 2,\n",
       "         'royalty': 4,\n",
       "         'became': 2,\n",
       "         'risky': 5,\n",
       "         'deal': 19,\n",
       "         'brings': 5,\n",
       "         'gen': 2,\n",
       "         'consumer': 18,\n",
       "         'printing': 4,\n",
       "         'ce': 5,\n",
       "         'aston': 1,\n",
       "         'kutcher': 1,\n",
       "         'star': 6,\n",
       "         'job': 29,\n",
       "         'kinda': 2,\n",
       "         'facebook': 1,\n",
       "         'social': 9,\n",
       "         'network': 4,\n",
       "         'came': 12,\n",
       "         'fb': 41,\n",
       "         'macd': 43,\n",
       "         'turning': 12,\n",
       "         'pi': 4,\n",
       "         'q': 66,\n",
       "         'mo': 24,\n",
       "         'ago': 25,\n",
       "         'bbby': 5,\n",
       "         'increase': 17,\n",
       "         'improvement': 4,\n",
       "         'di': 2,\n",
       "         'neg': 3,\n",
       "         'quiet': 6,\n",
       "         'carl': 1,\n",
       "         'icahn': 4,\n",
       "         'nfx': 94,\n",
       "         'paranoid': 2,\n",
       "         'acquired': 2,\n",
       "         'cannot': 3,\n",
       "         'obv': 7,\n",
       "         'phantom': 1,\n",
       "         'ive': 11,\n",
       "         'calling': 11,\n",
       "         'ever': 21,\n",
       "         'start': 65,\n",
       "         'given': 6,\n",
       "         'small': 46,\n",
       "         'ave': 29,\n",
       "         'poised': 11,\n",
       "         'area': 32,\n",
       "         'closely': 12,\n",
       "         'gdp': 14,\n",
       "         'slightly': 6,\n",
       "         'ema': 36,\n",
       "         'took': 21,\n",
       "         'scalp': 5,\n",
       "         'xe': 2,\n",
       "         'holder': 4,\n",
       "         'raise': 16,\n",
       "         'ask': 8,\n",
       "         'climb': 9,\n",
       "         'slowly': 7,\n",
       "         'regardless': 1,\n",
       "         'moving': 35,\n",
       "         'couldnt': 2,\n",
       "         'cope': 2,\n",
       "         'perhaps': 5,\n",
       "         'impossible': 3,\n",
       "         'continue': 22,\n",
       "         'work': 27,\n",
       "         'maco': 2,\n",
       "         'sense': 6,\n",
       "         'picked': 6,\n",
       "         'bit': 25,\n",
       "         'realistic': 2,\n",
       "         'undecided': 1,\n",
       "         'lift': 5,\n",
       "         'reversal': 23,\n",
       "         'carefully': 2,\n",
       "         'decide': 1,\n",
       "         'report': 43,\n",
       "         'sold': 45,\n",
       "         'giving': 12,\n",
       "         'finger': 3,\n",
       "         'care': 9,\n",
       "         'anymore': 4,\n",
       "         'lol': 19,\n",
       "         'va': 2,\n",
       "         'update': 13,\n",
       "         'push': 24,\n",
       "         'tried': 3,\n",
       "         'shake': 3,\n",
       "         'put': 99,\n",
       "         'hanging': 9,\n",
       "         'mind': 8,\n",
       "         'hb': 2,\n",
       "         'panic': 12,\n",
       "         'domain': 1,\n",
       "         'twitchy': 1,\n",
       "         'robot': 1,\n",
       "         'fundamental': 11,\n",
       "         'nvda': 32,\n",
       "         'hour': 28,\n",
       "         'vol': 51,\n",
       "         'explode': 5,\n",
       "         'hard': 23,\n",
       "         'ftc': 3,\n",
       "         'settlement': 1,\n",
       "         'worried': 7,\n",
       "         'gone': 9,\n",
       "         'oco': 1,\n",
       "         'door': 8,\n",
       "         'step': 20,\n",
       "         'nearly': 13,\n",
       "         'crazy': 9,\n",
       "         'anyone': 27,\n",
       "         'listens': 1,\n",
       "         'tool': 2,\n",
       "         'getting': 56,\n",
       "         'fueled': 2,\n",
       "         'aaps': 5,\n",
       "         'bby': 32,\n",
       "         'offer': 13,\n",
       "         'shave': 1,\n",
       "         'bid': 40,\n",
       "         'matter': 11,\n",
       "         'answer': 3,\n",
       "         'question': 6,\n",
       "         'red': 49,\n",
       "         'ove': 13,\n",
       "         'lot': 44,\n",
       "         'create': 11,\n",
       "         'delta': 10,\n",
       "         'candidate': 5,\n",
       "         'missed': 15,\n",
       "         'started': 16,\n",
       "         'ht': 4,\n",
       "         'second': 28,\n",
       "         'gap': 100,\n",
       "         'fill': 40,\n",
       "         'qcom': 19,\n",
       "         'introduces': 1,\n",
       "         'streamboost': 1,\n",
       "         'home': 22,\n",
       "         'connects': 1,\n",
       "         'seven': 3,\n",
       "         'device': 5,\n",
       "         'internet': 3,\n",
       "         'momo': 11,\n",
       "         'histogram': 3,\n",
       "         'bar': 30,\n",
       "         'noted': 2,\n",
       "         'hma': 1,\n",
       "         'unusual': 3,\n",
       "         'activity': 8,\n",
       "         'adbe': 6,\n",
       "         'oi': 21,\n",
       "         'ooks': 36,\n",
       "         'must': 13,\n",
       "         'stay': 25,\n",
       "         'basis': 9,\n",
       "         'monthly': 34,\n",
       "         'ticking': 2,\n",
       "         'seller': 18,\n",
       "         'sdjpy': 2,\n",
       "         'werent': 2,\n",
       "         'already': 22,\n",
       "         'ino': 4,\n",
       "         'accumulation': 10,\n",
       "         'znga': 42,\n",
       "         'fat': 3,\n",
       "         'juicy': 2,\n",
       "         'gdot': 7,\n",
       "         'ready': 35,\n",
       "         'recent': 34,\n",
       "         'spf': 2,\n",
       "         'ooking': 26,\n",
       "         'xf': 10,\n",
       "         'hungry': 2,\n",
       "         'heading': 12,\n",
       "         'ipad': 11,\n",
       "         'mini': 9,\n",
       "         'everywhere': 8,\n",
       "         'different': 5,\n",
       "         'none': 5,\n",
       "         'em': 4,\n",
       "         'explodes': 2,\n",
       "         'implodes': 2,\n",
       "         'minte': 1,\n",
       "         'vid': 2,\n",
       "         'mark': 15,\n",
       "         'nailing': 1,\n",
       "         'subject': 1,\n",
       "         'kkd': 4,\n",
       "         'krispy': 1,\n",
       "         'kreme': 1,\n",
       "         'doughnut': 2,\n",
       "         'inc': 13,\n",
       "         'ic': 1,\n",
       "         'xchange': 1,\n",
       "         'conference': 9,\n",
       "         'downgrade': 10,\n",
       "         'held': 15,\n",
       "         'pt': 26,\n",
       "         'picking': 6,\n",
       "         'food': 6,\n",
       "         'company': 79,\n",
       "         'dpz': 5,\n",
       "         'twenty': 1,\n",
       "         'enko': 5,\n",
       "         'view': 9,\n",
       "         'pf': 4,\n",
       "         'box': 15,\n",
       "         'size': 15,\n",
       "         'potential': 23,\n",
       "         'le': 16,\n",
       "         'csx': 7,\n",
       "         'vey': 5,\n",
       "         'coal': 3,\n",
       "         'confirming': 12,\n",
       "         'rail': 1,\n",
       "         'fin': 3,\n",
       "         'use': 15,\n",
       "         'lagging': 10,\n",
       "         'etest': 1,\n",
       "         'float': 10,\n",
       "         'continues': 35,\n",
       "         'base': 42,\n",
       "         'si': 39,\n",
       "         'rising': 23,\n",
       "         'pickup': 2,\n",
       "         'major': 33,\n",
       "         'financials': 6,\n",
       "         'ripping': 6,\n",
       "         'easy': 24,\n",
       "         'money': 64,\n",
       "         'approaching': 6,\n",
       "         'throughs': 1,\n",
       "         'dma': 19,\n",
       "         'crossing': 7,\n",
       "         'trading': 62,\n",
       "         'ma': 8,\n",
       "         'yeah': 2,\n",
       "         'slashing': 1,\n",
       "         'ay': 12,\n",
       "         'total': 7,\n",
       "         'sbx': 15,\n",
       "         'earththis': 1,\n",
       "         'kind': 4,\n",
       "         'stuff': 6,\n",
       "         'perk': 1,\n",
       "         'sorry': 16,\n",
       "         'five': 6,\n",
       "         'brainier': 1,\n",
       "         'sbac': 1,\n",
       "         'collar': 2,\n",
       "         'protection': 2,\n",
       "         'svu': 1,\n",
       "         'sure': 26,\n",
       "         'left': 15,\n",
       "         'cleared': 6,\n",
       "         'axti': 5,\n",
       "         'climbing': 3,\n",
       "         'upwards': 4,\n",
       "         'egov': 1,\n",
       "         'resting': 1,\n",
       "         'basing': 5,\n",
       "         'room': 8,\n",
       "         'bolly': 4,\n",
       "         'absorb': 1,\n",
       "         'atr': 1,\n",
       "         'tsa': 14,\n",
       "         'dismisses': 2,\n",
       "         'massachusetts': 2,\n",
       "         'state': 13,\n",
       "         'automobile': 1,\n",
       "         'dealer': 2,\n",
       "         'association': 1,\n",
       "         'awsuit': 3,\n",
       "         'trending': 6,\n",
       "         'appear': 2,\n",
       "         'slow': 17,\n",
       "         'yet': 23,\n",
       "         'prudent': 1,\n",
       "         'fe': 1,\n",
       "         'fired': 5,\n",
       "         'tick': 2,\n",
       "         'utility': 4,\n",
       "         'later': 13,\n",
       "         'rejected': 4,\n",
       "         'slight': 5,\n",
       "         'past': 23,\n",
       "         'enters': 1,\n",
       "         'yum': 1,\n",
       "         'either': 12,\n",
       "         'expe': 4,\n",
       "         'hog': 4,\n",
       "         'mon': 16,\n",
       "         'pii': 2,\n",
       "         'qih': 6,\n",
       "         'soda': 8,\n",
       "         'favorite': 6,\n",
       "         'though': 17,\n",
       "         'contraction': 4,\n",
       "         'wed': 5,\n",
       "         'spread': 16,\n",
       "         'oscillating': 2,\n",
       "         'ange': 4,\n",
       "         'suggest': 5,\n",
       "         'bbg': 4,\n",
       "         'cop': 3,\n",
       "         'eni': 1,\n",
       "         'jec': 3,\n",
       "         'ig': 7,\n",
       "         'sfy': 8,\n",
       "         'xop': 1,\n",
       "         'jds': 5,\n",
       "         'beautiful': 6,\n",
       "         'dip': 27,\n",
       "         'buyer': 24,\n",
       "         'ko': 26,\n",
       "         'trouble': 6,\n",
       "         'staying': 9,\n",
       "         'mako': 8,\n",
       "         'old': 15,\n",
       "         'advanced': 7,\n",
       "         'opt': 2,\n",
       "         'gnmk': 1,\n",
       "         'ege': 1,\n",
       "         'amn': 7,\n",
       "         'px': 9,\n",
       "         'aay': 1,\n",
       "         'sv': 26,\n",
       "         'simple': 3,\n",
       "         'fibonacci': 2,\n",
       "         'projection': 4,\n",
       "         'pipeline': 3,\n",
       "         'partnership': 2,\n",
       "         'ni': 5,\n",
       "         'mk': 3,\n",
       "         'pretty': 20,\n",
       "         'sum': 2,\n",
       "         'data': 28,\n",
       "         'retailer': 2,\n",
       "         'environment': 3,\n",
       "         'favor': 5,\n",
       "         'side': 25,\n",
       "         'welcome': 1,\n",
       "         'quality': 5,\n",
       "         'leader': 9,\n",
       "         'amh': 5,\n",
       "         'ocn': 10,\n",
       "         'egn': 3,\n",
       "         'hov': 5,\n",
       "         'amazing': 5,\n",
       "         'tale': 1,\n",
       "         'ford': 3,\n",
       "         'powerful': 2,\n",
       "         'dictate': 1,\n",
       "         'direction': 5,\n",
       "         'participate': 1,\n",
       "         'overbought': 14,\n",
       "         'vmed': 1,\n",
       "         'reverse': 5,\n",
       "         'tuesday': 9,\n",
       "         ...})"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counter class counts number of appearances of all words\n",
    "word_count = Counter()\n",
    "for tweet in san_df['Text']:\n",
    "    word_count.update(tweet)\n",
    "        \n",
    "# Create a dictionary that maps words to their one-hot vector indices\n",
    "vocab = [word for word in word_count if word_count[word] >= word_frequency_requirement] # vocab contains all words meeting the word frequency requirement.\n",
    "\n",
    "dictionary = {word : i+1 for i, word in enumerate(vocab)} # dicionary is a mapping of each vocab word to its vector index.The +1 reserves the zero index.\n",
    "\n",
    "dictionary[None] = 0 # Index 0 is reserved to be a blanket classification for all words below the word frequency requirement.\n",
    "\n",
    "word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tweet_length = max(len(x) for x in san_df['Text'])\n",
    "\n",
    "# Map tokenized tweets to lists of dictionary indices\n",
    "encoded_df = pd.DataFrame([[list(map(lambda w : dictionary.get(w, 0), tweet)) for tweet in san_df['Text']]]).T\n",
    "\n",
    "# Pad encoded tweets with trailing zeros\n",
    "encoded_df[0] = encoded_df[0].map( lambda x: x + [0] * (max_tweet_length - len(x)) )\n",
    "\n",
    "# Map encoded tweets to onehot vector sequences and recombine with sentiment data\n",
    "onehot_df = pd.DataFrame([\n",
    "    [F.one_hot(torch.LongTensor(enc_tweet), len(dictionary)) for enc_tweet in encoded_df[0]],\n",
    "    san_df['Sentiment']\n",
    "    ]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle data and split into training and testing data\n",
    "train_dataset = onehot_df.sample(frac = train_proportion)\n",
    "test_dataset = onehot_df.drop(train_dataset.index)\n",
    "\n",
    "train_size = train_dataset.shape[0]\n",
    "test_size = test_dataset.shape[0]\n",
    "\n",
    "train_tensor = torch.utils.data.TensorDataset(torch.stack(tuple(train_dataset[0])).type(torch.float32), torch.stack(tuple(train_dataset[1])))\n",
    "test_tensor = torch.utils.data.TensorDataset(torch.stack(tuple(test_dataset[0])).type(torch.float32), torch.stack(tuple(test_dataset[1])))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_tensor, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_tensor, batch_size = 1, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRN_model(nn.Module):\n",
    "    def __init__(self, num_input, num_hid, num_out):\n",
    "        super().__init__()\n",
    "        self.num_hid = num_hid\n",
    "        self.batch_size = 1\n",
    "        self.H0= nn.Parameter(torch.Tensor(num_hid))\n",
    "        self.W = nn.Parameter(torch.Tensor(num_input, num_hid))\n",
    "        self.U = nn.Parameter(torch.Tensor(num_hid, num_hid))\n",
    "        self.hid_bias = nn.Parameter(torch.Tensor(num_hid))\n",
    "        self.V = nn.Parameter(torch.Tensor(num_hid, num_out))\n",
    "        self.out_bias = nn.Parameter(torch.Tensor(num_out))\n",
    "\n",
    "        # Various initialisation schemes. Initialisation is important.\n",
    "        nn.init.zeros_(self.H0)\n",
    "        nn.init.xavier_normal_(self.W)\n",
    "        nn.init.xavier_normal_(self.U)\n",
    "        nn.init.zeros_(self.hid_bias)\n",
    "        nn.init.xavier_normal_(self.V)\n",
    "        nn.init.zeros_(self.out_bias)\n",
    "\n",
    "    def init_hidden(self):\n",
    "        H0 = torch.tanh(self.H0)\n",
    "        return(H0.unsqueeze(0))\n",
    " \n",
    "    def forward(self, seq):\n",
    "        seq_size, _ = seq.size()\n",
    "        h_t = self.init_hidden()\n",
    "        for t in range(seq_size):\n",
    "            x_t = seq[t]\n",
    "            c_t = x_t @ self.W + h_t @ self.U + self.hid_bias\n",
    "            h_t = torch.tanh(c_t)\n",
    "        output = h_t @ self.V + self.out_bias\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, criterion, optimizer, data, label):\n",
    "\n",
    "    loss = 0\n",
    "    outputs = []\n",
    "\n",
    "    for i in range(data.shape[0]):\n",
    "        net.init_hidden()\n",
    "\n",
    "        # Forward\n",
    "        output = net(data[i])\n",
    "\n",
    "        # Apply output nonlinearity. Log_softmax chosen as it is suited for classification tasks\n",
    "        outputs.append(F.log_softmax(output, dim=1))\n",
    "    \n",
    "    loss = criterion(torch.cat(outputs, dim=0), torch.squeeze(label,1))\n",
    "    \n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.data.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SRN_model(len(dictionary),hidden_layer_size,2)\n",
    "\n",
    "# Negative log likelihood loss. Suited for classification tasks.\n",
    "criterion = F.nll_loss\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01, loss = 0.663568, accuracy = 62.74%\n",
      "Epoch 02, loss = 0.662446, accuracy = 62.74%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [162], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39mfor\u001b[39;00m data, label \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m     11\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> 12\u001b[0m     loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m train(net, criterion, optimizer, data, label)\n\u001b[0;32m     14\u001b[0m \u001b[39m# Evaluate proportion of the test set correctly predicted.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m correct \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "Cell \u001b[1;32mIn [159], line 19\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(net, criterion, optimizer, data, label)\u001b[0m\n\u001b[0;32m     15\u001b[0m     outputs\u001b[39m.\u001b[39mappend(F\u001b[39m.\u001b[39mlog_softmax(output, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[0;32m     17\u001b[0m loss \u001b[39m=\u001b[39m criterion(torch\u001b[39m.\u001b[39mcat(outputs, dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m), torch\u001b[39m.\u001b[39msqueeze(label,\u001b[39m1\u001b[39m))\n\u001b[1;32m---> 19\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     21\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     23\u001b[0m \u001b[39mreturn\u001b[39;00m loss\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "plot_loss = []\n",
    "plot_correct = []\n",
    "\n",
    "num_batches = train_size//batch_size\n",
    "\n",
    "for e in range(epochs):\n",
    "    loss = 0.\n",
    "\n",
    "    # Trains on every training data item individually each epoch\n",
    "    for data, label in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        loss += train(net, criterion, optimizer, data, label)\n",
    "\n",
    "    # Evaluate proportion of the test set correctly predicted.\n",
    "    correct = 0\n",
    "    for data, label in test_loader:\n",
    "        output = net(data[0])\n",
    "        if (torch.argmax(output.data) == label[0][0]): correct += 1\n",
    "    accuracy = correct/test_size*100\n",
    "\n",
    "    # Append loss and accuracy results to lists for later plotting.\n",
    "    plot_loss.append(loss/num_batches)\n",
    "    plot_correct.append(accuracy)\n",
    "    \n",
    "    # Print loss and accuracy every epoch.\n",
    "    print(\"Epoch %02d, loss = %f, accuracy = %.2f%%\" % (e+1, loss / num_batches, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "plt.plot(plot_loss)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Avg. Loss per Epoch (on Training Set)')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(plot_correct)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy per Epoch (on Test Set)')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b941bf498f276488674bf31f1b0cc37176298e8d600eb280d450861b05bebb56"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
